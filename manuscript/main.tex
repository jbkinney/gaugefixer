%%
%% Copyright 2024 OXFORD UNIVERSITY PRESS
%%
%% This file is part of the 'mam-authoring-template Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version. The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'mam-authoring-template Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Microscopy and Microanalysis' document class `mam-authoring-template'
%% with bibliographic references
%%

\documentclass[unnumsec,webpdf,modern,large]{mam-authoring-template}%
\usepackage{amsmath,amssymb}
\usepackage{upgreek}
\usepackage{algorithm}
\usepackage{algpseudocode}
% natbib is already loaded by the document class
\bibliographystyle{plainnat}

% Suppress underfull hbox warnings
\hbadness=10000

% Better line breaking and character spacing
\usepackage{microtype}

\newcommand{\myfixed}{{\,\textrm{fixed}}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\myhier}{\textrm{hier}}
\newcommand{\myall}{\textrm{all}}
\newcommand{\mypair}{\textrm{pair}}
\newcommand{\myvar}{\textrm{var}}
\newcommand{\mygen}{\textrm{gen}}
\newcommand{\mysubsets}{\textrm{subsets}}
\newcommand{\mysource}{\textrm{source}}
\newcommand{\mysink}{\textrm{sink}}
\newcommand{\mytmp}{\textrm{tmp}}
\newcommand{\myinit}{\textrm{init}}

\usepackage{upgreek}

\graphicspath{{Fig/}}

\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%
\newtheorem{proposition}[theorem]{Proposition}%
\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%
\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}

\begin{document}

\journaltitle{bioR$\upchi$i$\upnu$}
\copyrightyear{2025}
\pubyear{2025}
\appnotes{Original Article}

\firstpage{1}

\title[GaugeFixer]{GaugeFixer: overcoming parameter non-identifiability in models of sequence-function relationships}

\author[1]{Carlos Martí-Gómez\ORCID{0000-0002-2042-843X}}
\author[1]{David M. McCandlish\ORCID{0009-0006-1474-0407}}
\author[1,$\ast$]{Justin B. Kinney\ORCID{0000-0003-1897-3778}}

\authormark{Martí-Gómez et al.}

\address[1]{\orgdiv{Simons Center for Quantitative Biology}, \orgname{Cold Spring Harbor Laboratory}, \orgaddress{\street{1 Bungtown Rd.}, Cold Spring Harbor, \postcode{11724}, \state{New York}, \country{United States}}}

\corresp[$\ast$]{Corresponding author. \href{email:jkinney@cshl.edu}{jkinney@cshl.edu}}

% \received{Date}{0}{Year}
% \revised{Date}{0}{Year}
% \accepted{Date}{0}{Year}

\abstract{Mathematical models that describe sequence-function relationships are widely used in computational biology. A key challenge when interpreting these models is that their parameters are not uniquely determined: many different parameter choices can encode the same sequence-function landscape. These ambiguities, known as ``gauge freedoms,'' must be resolved before parameter values can be meaningfully interpreted. Resolving gauge freedoms requires imposing mathematical constraints on parameters that remove these degrees of freedom, a procedure called ``fixing the gauge.'' We recently developed mathematical methods for fixing the gauge of a large class of commonly used models, but the direct computational implementation of these methods is often impractical due to the need for projection matrices whose memory requirements scale quadratically with the number of parameters. Here we introduce GaugeFixer, a Python package that exploits the specific mathematical structure of gauge-fixing projections to achieve linear scaling, thus enabling application to models with millions of parameters. As one application, we analyzed the local structure of peaks in an empirical fitness landscape for translation initiation. GaugeFixer reveals striking similarities, but also fine-scaled variation, in ribosome binding preferences at different positions relative to the start codon, thereby aiding the interpretation of an otherwise unwieldy fitness landscape. GaugeFixer thus fills an unmet need in the computational tools available for biologically interpreting sequence-function relationships. \\
\\
\textbf{Availability and implementation:} GaugeFixer is compatible with Python $\geq$ 3.10 and can be installed using the pip package. Documentation is provided at http://gaugefixer.readthedocs.io. Source code is available at http://github.com/jbkinney/gaugefixer, as are the scripts used to carry out the analyses presented here.
}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Computational biology routinely involves the use of models that describe the quantitative relationship between biological sequences (DNA, RNA, or protein) and measurable biological activities \citep{Kinney2019jc}. For example, quantitative models of sequence-function relationships have been used to predict the locations of transcription factor binding sites in promoters and enhancers~\citep{Stormo2013}, the locations of splice sites in pre-mRNA transcripts~\citep{Yeo2004}, structural contacts between residues in folded proteins~\citep{Marks2012}, and the effects of human genetic variation on protein function~\citep{Hopf2017}. One application of growing interest is the modeling of data from high-throughput mutagenesis experiments~\citep{Kinney2010tn, Mogno2013cf, Belliveau2018kr, Otwinowski2018jj, Faure2022aa, Zhou2022, Tareen2022dh, Faure:2024so, MartiGomez2025aa, Zhou2025}. 

A common way to mathematically represent sequence-function relationships is to use generalized one-hot models \citep{Posfai2025aa, Posfai2025bb}. In these models, each sequence is represented as a set of binary features, each feature indicating the presence or absence of a specific subsequence at a specific set of positions. For example, additive features indicate individual characters (nucleotides or amino acids) at individual positions, pairwise features indicate pairs of characters at pairs of positions, and so on. Each parameter of a generalized one-hot model quantifies the effect that a corresponding sequence feature has. Although generalized one-hot models are linear functions of their parameters, they can represent arbitrarily complex sequence-function landscapes~\citep{Posfai2025aa}.

A fundamental challenge often arises when one attempts to interpret the parameters of generalized one-hot models: except in unusual cases, these parameters are not uniquely determined by the sequence-function landscape the model describes \citep{Posfai2025bb}. As a consequence, the values of model parameters cannot be uniquely determined by data, even in principle. This non-identifiability occurs because the binary feature vectors that represent sequences do not span the full space in which they live. Consequently, a nontrivial set of parameter vectors will yield identical model predictions. These parameter vectors differ by what are called ``gauge freedoms'' -- directions in parameter space that are orthogonal to all binary feature vectors. 

The ambiguity that gauge freedoms produce must be resolved before the values of model parameters can be interpreted, or before the parameters of two different models can be compared. This resolution is achieved by imposing additional mathematical constraints that, together with the predicted landscape, select a unique set of parameter values. This procedure is called ``fixing the gauge''. Different choices of constraints yield different gauges, each providing a distinct mathematical representation of the same underlying sequence-function relationship reflecting a distinct interpretation of the parameters.

The importance of gauge freedoms was first recognized in theoretical physics and is very well understood in that context \citep{Jackson2001dk}. Until recently, however, gauge freedoms in sequence-function relationships had received little attention. A diffuse body of work had discussed specific approaches for handling gauge freedoms in specific modeling contexts, e.g., in additive models for transcription factor binding specificity \citep{Kinney:2007dh, Stormo:2011jb, Rube:2022ye}, pairwise models of protein fitness landscapes \citep{Weigt:2009th, Marks:2011aa, Ekeberg:2013bb, Barton:2016aa, Cocco:2018aa, Haldane:2019di, Gerardos:2022aa, Hsu:2022ek}, and all-order interaction models \citep{Zamuner:2021gy, Feinauer:2022aa, Feinauer:2022bb}. The issue had also arisen implicitly in the literature concerning alternative parameterizations for genetic interactions \citep{Poelwijk2019gy, metzger2024epistasis, Park:2023aa, Dupic2024:aa, Park2024.09.17.613512, Faure:2024gy}. However, a unified understanding of gauge freedoms in sequence-function relationships had yet to be developed.

To address this need, we recently developed a comprehensive mathematical theory of gauge freedoms in generalized one-hot models \citep{Posfai2025aa, Posfai2025bb}. In particular, \citet{Posfai2025aa} introduced a specific family of gauges that can be imposed through the projection of model parameters via matrix multiplication. These gauges have a simple mathematical form and include nearly all of the gauges used in the prior literature. However, carrying out this matrix operation requires storing and manipulating dense projection matrices, the sizes of which scale quadratically with the number of model parameters, and is impractical for models with more than a few thousand parameters.

Here we introduce GaugeFixer, an open-source Python package that overcomes this computational limitation. By exploiting the mathematical structure of generalized one-hot models and the projection matrices described by \citet{Posfai2025aa}, GaugeFixer achieves linear scaling in both memory and computation time, enabling rapid gauge fixing for models with millions of parameters. To demonstrate its utility, we apply GaugeFixer here to a fitness landscape for Shine-Dalgarno sequences, represented by a model with nearly 2 million parameters \citep{Kuo2020,MartiGomez2025aa}. This analysis illustrates how GaugeFixer can be used to reveal shared sequence requirements across different ribosome binding registers, a phenomenon that is otherwise difficult to discern within such complex sequence-function landscapes. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Generalized one-hot models}

We consider generalized one-hot models that predict a scalar function $f(s)$ for sequences $s$ of fixed length $L$. Of particular interest among these models are all-order models, which describe interactions of every order from 0 through L. Such models can represent any possible sequence-function relationship, but the number of parameters they require grows exponentially with sequence length. It is therefore common to use models that include only interactions up to a specified order ($K$-order models) or only between nearby positions (nearest-neighbor, or $K$-adjacent models). These are examples of hierarchical models, a class of generalized one-hot models that remain tractable for longer sequences while still capturing important biological dependencies. See Methods for more information.

\subsection{Minimal gauge fixing example}
We now illustrate the process of gauge fixing using a minimal example of a sequence-function landscape. Consider sequences of length $L=1$ built using a two-character alphabet $\{\textrm{A},\textrm{B}\}$. There are only two possible sequences in this example: $s=\textrm{A}$ and $s=\textrm{B}$. Consequently, the landscape $f(s)$ has only two degrees of freedom. The corresponding all-order model, however, has three parameters---a constant-effect parameter ($\theta_0$) and two additive parameters ($\theta_1^\textrm{A}$ and $\theta_1^\textrm{B}$) that describe the effect of either possible character at position 1 in the sequence. The all-order model therefore exhibits one gauge freedom. Fixing the gauge involves introducing an additional constraint that removes this degree of freedom, leading each valid choice of parameters to produce a unique sequence-function landscape.

Figure~\ref{fig:sd}A illustrates this example. The orange dot shows one choice of parameter vector, $\vec{\theta}=[\theta_0, \theta_1^\textrm{A}, \theta_1^{B}] = [0,0,2]$. This choice yields the following sequence-function landscape: $f(A)=\theta_0 + \theta_1^\textrm{A}=0$, $f(B)=\theta_0 + \theta_1^\textrm{B}=2$. There are, however, an infinite number of equivalent parameter vectors that yield this same landscape, namely vectors of the form $[z, -z, 2-z]$ where $z$ is any real number (red line). Fixing the gauge involves specifying an additional constraint that selects a single point on this line. The blue plane in Figure~\ref{fig:sd}A represents one such constraint: the zero-sum gauge, which requires that the additive parameters sum to zero at each position ($\theta_1^\textrm{A} + \theta_1^\textrm{B}=0$). The resulting gauge-fixed parameters (orange dot) lie at the intersection of the line of equivalent parameters with the zero-sum plane ($\vec{\theta}_\textrm{fixed} = [1,-1,1]$; green dot). Note that no choice of parameters in the zero-sum gauge other than $\vec{\theta}_\textrm{fixed}$ will yield the specific landscape $f(A)=0$, $f(B)=2$.

\subsection{Families of gauges}

In previous work~\citep{Posfai2025aa}, we introduced a family of gauges for the all-order interaction model. These gauges are parameterized by two quantities: a non-negative number $\lambda$ and a probability distribution $\pi$ over sequences. $\lambda$ controls how much explanatory power is allocated across interaction orders, while $\pi$ specifies the distribution of sequences against which parameter effects are expressed. This $\lambda,\pi$ family of gauges has multiple attractive properties. In particular, it encompasses the most commonly used gauges in the literature including the trivial gauge, the euclidean gauge, the equitable gauge, the zero-sum gauge, and the wild-type gauge. See \citet{Posfai2025aa} for details. 

A particularly useful subset of gauges in this family are the hierarchical gauges, which are obtained in the limit where $\lambda$ approaches infinity. In these gauges, lower-order terms explain as much of the landscape's variance as possible, while higher-order interaction terms capture only residual variation that cannot be attributed to lower-order effects. Unlike other gauges in the $\lambda,\pi$ family, hierarchical gauges can be applied to all hierarchical models. The values of model parameters in hierarchical gauges also have a natural interpretation: each parameter represents the average effect of introducing specific characters at specific positions, compared to the effect expected from lower-order terms, when sequences are drawn from the distribution $\pi$. By choosing different distributions $\pi$, one can observe how sequence-function relationships vary across different regions of sequence space. For example, a uniform distribution yields global averages, whereas distributions concentrated near particular sequences reveal local landscape structure. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
    \centering
    \includegraphics{figures/Figure.pdf}
    \caption{Illustration of gauge-fixing and demonstration of GaugeFixer. 
    (A) Minimal example of gauge fixing. Shown is the space of all possible three-dimensional parameter vectors, $\vec{\theta}=[\theta_0, \theta_1^\textrm{A}, \theta_1^\textrm{B}]$, for the all-order interaction model on sequences of length $L=1$ built from the alphabet $\set{A,B}$. Orange dot: initial choice of $\vec{\theta} = [0,0,2]$, which yields $f(A)=0$, $f(B)=2$. Red line: parameter vectors equivalent to $\vec{\theta}$. Blue plane: parameter vectors in the zero-sum gauge, i.e., that satisfy $\theta_1^\textrm{A} + \theta_1^\textrm{B} = 0$. Green dot: gauge-fixed parameters $\vec{\theta}_{\myfixed} = [1,-1,1]$. 
    (B,C) Algorithm performance when fixing the gauge of all-order and pairwise protein  models with increasing number of parameters. Shown are the runtime (B) and peak memory (C) requirements for GaugeFixer and for standard matrix multiplication. Error bars represent the standard deviation in runtime and memory usage over 10 projections of parameter vectors drawn i.i.d. from a normal distribution.
    (D) Sequence logos showing the probability distributions $\pi$ corresponding to different peaks in the Shine-Dalgarno fitness landscape measured by \citet{Kuo2020} and modeled by \cite{MartiGomez2025aa}. Each distribution has a fixed AGGAG motif at a specific register relative to the start codon. 
    (E,F,G) Gauge-fixed constant (E), additive (F), and pairwise (G) parameters in the hierarchical gauge associated with each register. Horizontal dashed lines in (E) represent the average phenotype across all possible sequences (red) and the phenotype of the wild-type sequence AAGGAGGUG (green), which occurs in the 5'UTR of the \textit{dmsC} gene of \textit{Escherichia coli}.
    (H) Scatterplots comparing the values of gauge-fixed parameters observed in the core region at different registers.}
    \label{fig:sd}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The GaugeFixer algorithm}

Fixing the gauge requires projecting parameter vectors onto lower-dimensional subspaces. The projection matrices for gauges in the $\lambda,\pi$ family have a special structure: they can be written as Kronecker products of $L$ much smaller matrices, one matrix for each sequence position~\citep{Posfai2025aa}. GaugeFixer exploits this factorization to compute projections without ever constructing the full projection matrix. This is possible because matrix-vector products involving a Kronecker product of $L$ matrices can be computed iteratively, applying one small matrix at a time to successive dimensions of the parameter array~\citep{MartiGomez2025aa}. This reduces both the memory requirements and computation time from O($M^2$) to O($M$), where $M$ is the number of model parameters. For hierarchical models more generally, GaugeFixer decomposes the model into a sum of all-order models restricted to subsets of positions, applies the efficient projection algorithm to each, and sums the results together. See Methods for details.

Figures~\ref{fig:sd}B,C show the performance advantage of this approach. Compared to direct matrix multiplication, GaugeFixer achieves orders of magnitude improvement in both runtime and memory usage. This makes it possible to gauge-fix models with millions of parameters in just a few seconds on a standard laptop computer. By contrast, gauge-fixing becomes impractical beyond about $10^4$ parameters when using explicit projection matrices. 

\subsection{Analysis of the Shine-Dalgarno fitness landscape}

To illustrate the utility of GaugeFixer, we analyzed the fitness landscape of the Shine-Dalgarno (SD) sequence, a motif in bacterial messenger RNA that facilitates translation initiation by base-pairing with the 3' tail of the 16S ribosomal RNA~\citep{Shine1975}. \citet{Kuo2020} previously measured the translational activity of nearly every possible 9-nucleotide RNA sequence. Subsequent modeling efforts inferred a sequence-function landscape from this data, corresponding to an all-order model with $5^9=1,953,125$ parameters~\citep{Zhou2022, MartiGomez2025aa}. This landscape contains multiple fitness peaks corresponding to the canonical AGGAG motif positioned in different registers relative to the start codon.

We used GaugeFixer to quantitatively characterize the local structure around fitness peaks in the landscape inferred by \citet{MartiGomez2025aa}. For each peak we defined a distribution $\pi$ that fixes the AGGAG motif in the corresponding register while randomly drawing characters at the remaining positions (Figure~\ref{fig:sd}D). We then imposed the hierarchical gauge corresponding to each distribution $\pi$ and examined the resulting parameter values. In this gauge, the constant, additive, and pairwise parameters can be respectively interpreted as the average phenotype, average single-nucleotide effect, and average epistatic effect observed when mutations are introduced into sequences randomly drawn from $\pi$. We emphasize that these different parameter values, corresponding to different gauges, are simply different representations of the same model. 

The constant term, $\theta_0$, represents the mean fitness of sequences with AGGAG in the specified register. We find that this value is highest for registers $-$12 and $-$11, consistent with known optimal spacing requirements for translation initiation (Figure~\ref{fig:sd}E). In register $-$9, by contrast, the mean fitness is much lower, indicating markedly lower translation on average.

The additive parameters in the core region, shown in Figure~\ref{fig:sd}F, reveal how individual nucleotide mutations away from the AGGAG motif affect translational efficiency in each register. As expected, these mutations are overwhelmingly deleterious. The effects are also remarkably consistent across registers, though some differences emerge near the boundaries.

The pairwise interaction parameters in the core region, shown in Figure~\ref{fig:sd}G, capture the effects of mutating pairs of nucleotides within the AGGAG motif beyond what additive effects alone predict. These interactions are also remarkably consistent across registers. Predominantly positive values are observed, indicating that combinations of mutations tend to be less deleterious than expected from their individual effects, one hallmark of global epistasis \citep{Otwinowski2018jj,Kinney2019jc}.

Finally, we compared the constant, additive, and pairwise parameters in the core region across registers (Figure~\ref{fig:sd}H). The results show that neighboring registers tend to have more similar parameters, while more distant registers show greater divergence. This smooth variation suggests that ribosomal binding preferences change gradually as a function of distance from the start codon.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Here we introduced GaugeFixer, a Python package that implements a computationally efficient algorithm for removing gauge freedoms from generalized one-hot models of sequence-function relationships. By exploiting the Kronecker factorization of projection operators and the specific mathematical structure of the models, GaugeFixer dramatically reduces runtime and memory requirements, thus enabling rapid gauge fixing for models with millions of parameters. 

We wish to emphasize that gauge fixing is fundamentally different from parameter inference. Both procedures are an essential part of modeling sequence-function relationships, but they serve orthogonal purposes. Inference is the process of identifying parameters that make a model's predictions best fit one's data, but without regard to parameter interpretation. Gauge-fixing, by contrast, alters model parameters in ways that have no effect on model predictions, but which are important for the interpretation of those parameters. GaugeFixer makes this distinction explicit by providing utilities to convert precomputed parameter vectors into any chosen gauge. A related but more subtle point is that some regularization schemes and/or prior distributions used during inference yield parameters in specific gauges \citep{Posfai2025aa,Petti2025aa}. This does not, however, eliminate the need for post-inference gauge fixing. On the contrary, the most common/effective regularization methods often produce parameters in gauges that are not consistent with how one wishes to interpret those parameters. 

Although GaugeFixer is designed to work with specific classes of linear models (all-order models and hierarchical models), it can also be applied to nonlinear and nonparametric models, such as neural networks or Gaussian processes. This is done by representing (or approximating) the model-predicted landscape using an all-order (or hierarchical) model, then applying GaugeFixer to the parameters of that model. Here we demonstrated this capability by analyzing a Shine-Dalgarno fitness landscape modeled using Gaussian process regression~\citep{Zhou2022,MartiGomez2025aa}. \citet{MartiGomez2025aa} recently described gpmap-tools, a Python package that enables such Gaussian process modeling when sequences are short enough to enumerate all possible interaction terms. GaugeFixer complements this functionality by enabling post-hoc computation of gauge-fixed parameters for any of these models. We note, however, that recent theoretical results suggest the possibility of directly computing the posterior distribution over specific gauge-fixed parameters using Gaussian processes defined over sequences of arbitrary length, thus bypassing the need to first construct explicit all-order models \citep{Petti2025aa}. 

Different gauges have different advantages when interpreting model parameters. For instance, the influence of global epistasis is more evident when parameters are represented in the wild-type gauge, whereas using additive models to illustrate the specificities of transcription factors, or computing contact maps in pairwise interaction models, typically requires the models to be in the zero-sum gauge~\citep{Kinney:2007dh, Stormo:2011jb, Rube:2022ye, Marks:2011aa,Ekeberg:2013bb}. Gauge-fixing is conceptually related to other techniques for interpretation of neural network models such as global importance analysis~\citep{Koo2021}, which quantifies the average effect of placing a specific sequence pattern, e.g., a transcription factor binding site, within random genetic backgrounds. While this method has the advantage that it can be applied to any model, gauge-fixing enables exact computation, not only of the average effect of a sequence pattern over random genetic backgrounds, but also the expected effects of mutations and their combinations. By doing so, gauge-fixing facilitates the investigation of how mutational effects and their interactions change across different regions of sequence space, providing an intuitive way to interpret the higher-order interactions that make them different. 

GaugeFixer thus provides a high-performance software library for fixing the gauge of commonly used sequence-to-function models, filling an important gap in the computational tools available for interpreting sequence-function relationships.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Generalized one-hot models}

We consider scalar-valued sequence-function relationships $f(s)$ where $s$ is a sequence of fixed length $L$ built from an alphabet $\mathcal{A} = \set{c_1, c_2, \ldots, c_\alpha}$ comprising $\alpha$ distinct characters.\footnote{GaugeFixer actually supports sequences built using different alphabets at different positions, with no need for these alphabets to be of the same size. The formulas in this section generalize in a straightforward way to accommodate this more general use case.} Let $S = \set{1,2,\ldots,L}$ denote the set of positions within $s$. 
Linear models of sequence-function relationships have the form
\begin{equation}
f(s) = \vec{\theta} \cdot \vec{x}(s),
\end{equation}
where $\vec{\theta}$ is a vector of model parameters and $\vec{x}(s)$ is a vector of sequence-dependent features. 

This work focuses on a specific class of linear models, the generalized one-hot models described by \citet{Posfai2025aa,Posfai2025bb}. In these models, the sequence-dependent features are binary indicator functions over subsequences. Formally, each feature is given by 
\begin{equation}
x^u_U(s) = \left\{ \begin{array}{cl} 1 & \textrm{if~} s[U] = u \\ 0 & \textrm{otherwise} \end{array} \right.,
\end{equation}
where $U \subseteq S$ is a subset of positions, $s[U]$ indicates the subsequence of $s$ that occurs at these positions, and $u$ is a sequence of length $|U|$ (i.e., $u \in \mathcal{A}^{|U|}$).\footnote{Sets of positions are called ``orbits'' in \citep{Posfai2025aa,Posfai2025bb}} Generalized one-hot models also require that $\vec{x}(s)$ be equivariant under position-specific character permutations~\citep{Posfai2025bb}. This means that if $x_U^u$ occurs in $\vec{x}$ for some $U$ and subsequence $u$, so must $x_U^{u'}$ for every possible subsequence $u'$ of size $|U|$. The set of features in a generalized one-hot model is therefore defined by an alphabet $\mathcal{A}$ and a collection of position sets $V = \set{U_1, U_2, \ldots, U_n}$ via
\begin{equation}
    f(s) = \sum_{U\in V} \sum_{u \in \mathcal{A}^{|U|}} \theta_U^u x_U^u(s). 
\end{equation}

\subsection{All-order models and hierarchical models}

All-order models are generalized one-hot models that include features for all possible subsequences at all possible sets of positions. This means that $V$ includes every possible position set $U \subseteq S$. $V$ is therefore the powerset of $S$, denoted $V=\mathcal{P}(S)$. Because the subsets of $S$ fully define $V$, we say that $S$ is the generating position set of $V$. 

Hierarchical models are more general than all-order models. Each hierarchical model is defined by one or more generating position sets $S' \subseteq S$, the subsets of which together comprise $V$. Formally, if $W = \set{S'_1, S'_2, \ldots, S'_m}$ denotes the set of generating position sets, then $V=\bigcup_{S' \in W} \mathcal{P}(S')$ is the union of the powersets of these generating position sets. Common examples of hierarchical models include additive models (defined by all position sets of size 0 and 1), pairwise models (all position sets up to size 2), nearest-neighbor models (same as pairwise but with size-2 position sets restricted to adjacent positions), $K$-order models (all position sets up to size $K$), and $K$-adjacent models (all position sets up to size $K$ but restricted $K$ adjacent positions).\footnote{\citet{Posfai2025bb} adopted a different definition of $K$-adjacent models, one that makes these models non-hierarchical. We favor the present definition, which is hierarchical and thus amenable to gauge fixing using hierarchical gauges.}

\subsection{Gauge-fixing projection matrices}

The $\lambda,\pi$ family is a set of gauges for the all-order interaction model. It is parameterized by a non-negative number $\lambda$ and a probability distribution $\pi$ over sequences that factorizes over positions. This family includes many commonly used gauges. In particular, the hierarchical gauges correspond to setting $\lambda = \infty$ and generalizes two commonly used gauges. The zero-sum gauge, commonly used when modeling transcription factor binding to DNA, is the hierarchical gauge that results from $\pi$ being uniform. Similarly, defining $\pi$ to be an indicator function for a specific sequence yields the wild-type gauge, which is commonly used in studies of protein fitness landscapes. 

Fixing the gauge of all-order models is accomplished by linear projection. In this case there are $M = (\alpha + 1)^L$ parameters. Given an $M$-dimensional vector $\vec{\theta}$ of initial parameter values, one can obtain the gauge-fixed parameters $\vec{\theta}_{\myfixed}$ via multiplication with an appropriate $M \times M$ projection matrix $P$ (which depends on $\lambda$ and $\pi$): 
\begin{align}
    \vec{\theta}_{\myfixed} &= P \vec{\theta}. \label{eq:theta_all_fixed}
\end{align}
Importantly, the projection matrix can be written as a Kronecker product of position-specific matrices:
\begin{align}
    P &= P_1 \otimes P_2 \otimes \cdots \otimes P_L, \label{eq:P_all_factorization}
\end{align}
where each $P_l$ is the $(\alpha + 1) \times (\alpha + 1)$ matrix
\begin{align}
P_l = \begin{pmatrix}
\eta & \pi_l^{c_1} \eta & \pi_l^{c_2} \eta & \cdots & \pi_l^{c_{\alpha}} \eta \\
1 - \eta & 1 - \pi_l^{c_1} \eta & - \pi_l^{c_2} \eta & \cdots & - \pi_l^{c_{\alpha}} \eta \\
1 - \eta & - \pi_l^{c_1} \eta & 1 - \pi_l^{c_2} \eta & \cdots & - \pi_l^{c_{\alpha}} \eta \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 - \eta & - \pi_l^{c_1} \eta & - \pi_l^{c_2} \eta & \cdots & 1 - \pi_l^{c_{\alpha}} \eta \\
\end{pmatrix}, \label{eq:kron_prod_all_order_P}
\end{align}
$\pi_l^c$ is the probability of character $c$ occurring at position $l$, and $\eta = \lambda/(1+\lambda)$. See \citet{Posfai2025aa} for details. 

Although the $\lambda,\pi$ gauges are defined in the context of all-order models, the specific class of hierarchical gauges can also be applied to the more general class of hierarchical models. This is done by treating each hierarchical model on sequences of length $L$ as an all-order model on sequences of the same length that has unused parameters set to zero. This works because hierarchical gauges preserve these sets of zero-valued parameters. Other $\lambda,\pi$ gauges do not preserve these zero-valued parameters, and therefore are restricted in their application to all-order models only. 

\subsection{Efficient gauge fixing via Kronecker factorization}

To compute $P \vec{\theta}$, we first reshape $\vec{\theta}$ to be an $L$-dimensional tensor having size $(\alpha+1)$ along each dimension. The expression in Eq. \ref{eq:theta_all_fixed} then becomes
\begin{align}
[\vec{\theta}_{\myfixed}]_{i_1 \cdots i_L} &= \sum_{j_1 \cdots j_L} [P_1]_{i_1 j_1} \cdots [P_L]_{i_L j_L} [\vec{\theta}]_{j_1 \cdots j_L}. \label{eq:theta_fixed_kron}
\end{align}
We compute Eq.\ \ref{eq:theta_fixed_kron} iteratively: first we define $\vec{\theta}^{(0)} = \vec{\theta}$; then for $l=1,2,\cdots,L$ we compute
\begin{align}
\vec{\theta}^{(l)}_{i_1 \cdots i_L} = \sum_{j_l} [P_l]_{i_l j_l} [\vec{\theta}^{(l-1)}]_{i_1 \cdots i_{l-1} j_l i_{l+1} \cdots i_L}, \label{eq:P_l_prod}
\end{align}
which ultimately yields $\vec{\theta}_\myfixed = \vec{\theta}^{(L)}$. This computation is formalized in Algorithm \ref{alg:fix_gauge_all_orders}, which uses a single intermediate parameter vector $\vec{\psi}$ to avoid storing all $\vec{\theta}^{(l)}$ simultaneously. Algorithm \ref{alg:fix_gauge_all_orders} has a computational complexity of O($L(\alpha+1)M$). This compares favorably to the computational complexity of direct matrix multiplication of $\vec{\theta}$ by $P$, which is O($M^2$). The memory requirements of Algorithm \ref{alg:fix_gauge_all_orders} also scale linearly with $M$, as opposed to quadratically with $M$ for direct matrix multiplication. 

\begin{algorithm}
    \caption{Fixing the gauge of all-order models}\label{alg:fix_gauge_all_orders}
    \begin{algorithmic}[1]
        \Require $\lambda,\pi,\vec{\theta}_\myinit$ 
        \State $\vec{\psi} \gets \operatorname{reshape}(\vec{\theta}_\myinit)$ 
        \For{$l=1$ to $L$}
            \State $P_l \gets \operatorname{ProjectionMatrix}(\lambda, \pi_l)$ \Comment{Equation~\ref{eq:kron_prod_all_order_P}}
            \State $\vec{\psi}\gets \operatorname{tensordot}(P_l, \vec{\psi}, l)$ \Comment{Equation~\ref{eq:P_l_prod}}
        \EndFor
        \State $\vec{\theta}_\myfixed \gets \operatorname{reshape}(\vec{\psi})$
    \end{algorithmic}
    \Return $\vec{\theta}_\myfixed$
\end{algorithm}

\subsection{Hierarchical model decomposition}

To project a hierarchical model into a hierarchical gauge, we leverage the fact that the parameters of the model can be expressed as a sum of the parameters of multiple all-order models, each restricted to one of the generating position sets. Let $\vec{\theta}$ be the parameter vector of the hierarchical model expressed as an $(\alpha+1)^L$-dimensional all-order parameter vector (with unused parameters set to zero), and let $W$ denote the set of generating position sets. We first decompose $\vec{\theta}$ as 
\begin{equation}
    \vec{\theta} = \sum_{S' \in W} \vec{\theta}_{S'} \label{eq:theta_decomposition}
\end{equation}
where each $\vec{\theta}_{S'}$ is an all-order parameter vector for the position set $S'$, i.e., has nonzero parameters $\theta^u_U$ only for $U \subseteq S'$. We note that there are multiple ways to carry out this decomposition, all of which yield the same gauge-fixed parameters. The gauge-fixed parameters are then computed as
\begin{equation}
    \vec{\theta}_\myfixed = \sum_{S' \in W} P \vec{\theta}_{S'} \label{eq:theta_fixed_decomposition}
\end{equation}
Importantly, each term on the right-hand side can be computed using only the Kronecker factors $P_l$ corresponding to positions $l \in S'$. Thus, there is never any need to represent the full $(\alpha+1)^L$-dimensional vectors $\vec{\theta}$, $\vec{\theta}_{S'}$, or $\vec{\theta}_\myfixed$. 

Algorithm \ref{alg:fix_gauge_hierarchical} formalizes this procedure. Here, $\vec{\theta}[S']$ indicates an $(\alpha+1)^{|S'|}$-dimensional vector composed only of the elements $\theta_U^u$ for which $U \subseteq S'$, and $\pi[S']$ represents the marginal distribution $\pi$ over subsequences on $S'$. Note that the iterative form of this algorithm allows us to avoid simultaneously storing the nonzero elements of all $\vec{\theta}_{S'}$ vectors. 

\begin{algorithm}
    \caption{Fixing the gauge of hierarchical models.}\label{alg:fix_gauge_hierarchical}
    \begin{algorithmic}[1]
        \Require $\pi,\vec{\theta}_\myinit,W$
        \State $\vec{\theta}_{\myfixed} \gets \vec{0}$
        \State $\vec{\theta}_{\mytmp} \gets \vec{\theta}_\myinit$
        \For{$S'$ in $W$}
            \State $\vec{\omega} \gets \vec{\theta}_\mytmp[S']$ \Comment{Note: $\vec{\omega} = \vec{\theta}_{S'}[S']$}
            \State $\vec{\omega}_\myfixed \gets \operatorname{FixAllOrders}(\infty, \pi[S'], \vec{\omega})$ \Comment{Algorithm~\ref{alg:fix_gauge_all_orders}}
            \State $\vec{\theta}_\myfixed[S'] \gets \vec{\theta}_\myfixed[S'] + \vec{\omega}_\myfixed $
            \State $\vec{\theta}_\mytmp[S'] \gets \vec{0}$
        \EndFor
    \end{algorithmic}
    \Return $\vec{\theta}_{\myfixed}$
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Competing interests}
The authors declare no competing interests. 

\section{Author contributions statement}
C.M-G.\ and J.B.K.\ conceived the project, wrote the package, and performed the research. C.M-G., D.M.M, and J.B.K.\ wrote the manuscript. D.M.M.\ and J.B.K.\ supervised the research. 

\section{Acknowledgments}
This work was supported by NIH grants R01HG011787 (J.B.K, D.M.M.), R35GM133777 (J.B.K.), and R35GM133613 (D.M.M., C. M-G.). Computational equipment was supported by NIH grant S10OD028632.

\bibliography{reference}
\end{document}

